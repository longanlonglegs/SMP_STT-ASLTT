{"cells":[{"cell_type":"markdown","metadata":{"id":"su4GZl8n2vcB"},"source":["This code is a live Speech-To-Text (STT) model utilizing OpenAI Whisper model. It can accurately transcribe live audio from chosen audio inputs into text printed on the shell with little delay (<1s).\n","\n","Improvements to be done:\n","- Combine old AudioSegments with new input so no wrong transcription\n","- Allow user to toggle start / stop using buttons or keyboard inputs\n","- Allow user to select audio input directly from program\n","- increase performance of live STT model\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"id":"UXJc3NphT01E","executionInfo":{"status":"ok","timestamp":1723353115953,"user_tz":-480,"elapsed":22036,"user":{"displayName":"Logan","userId":"18304062198620462332"}},"outputId":"b253bc81-12ff-44be-ca49-99eb4fb53fe9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/openai/whisper.git\n","  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-inki74i1\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-inki74i1\n","  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.60.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.26.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.1+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.5)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.3.0)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.7.0)\n","Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.15.4)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.43.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.5.15)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.32.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2024.6.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117) (12.6.20)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.7.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n","Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Ign:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy Release\n","Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Fetched 257 kB in 1s (258 kB/s)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","45 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","portaudio19-dev is already the newest version (19.6.0-1.1).\n","python-all-dev is already the newest version (2.7.18-3).\n","0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n","Requirement already satisfied: anvil-uplink in /usr/local/lib/python3.10/dist-packages (0.5.1)\n","Collecting argparse (from anvil-uplink)\n","  Using cached argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (1.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (1.16.0)\n","Requirement already satisfied: ws4py-sslupdate in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (0.5.1b0)\n","Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n","Installing collected packages: argparse\n","Successfully installed argparse-1.4.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["argparse"]},"id":"16fe8550972440b7ad1d3de22f2af030"}},"metadata":{}}],"source":["!pip install git+https://github.com/openai/whisper.git\n","!sudo apt update && sudo apt install ffmpeg\n","!apt-get install portaudio19-dev python-all-dev\n","!pip -q install pydub\n","!pip install anvil-uplink"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"nMEiHoYCW1wH","colab":{"base_uri":"https://localhost:8080/","height":297},"executionInfo":{"status":"error","timestamp":1723353675119,"user_tz":-480,"elapsed":35816,"user":{"displayName":"Logan","userId":"18304062198620462332"}},"outputId":"86de5fa2-919b-4e0e-8fb7-bf157382e2dd"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n","const b2text = blob => new Promise(resolve => {\n","  const reader = new FileReader()\n","  reader.onloadend = e => resolve(e.srcElement.result)\n","  reader.readAsDataURL(blob)\n","})\n","var record = time => new Promise(async resolve => {\n","  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n","  recorder = new MediaRecorder(stream)\n","  chunks = []\n","  recorder.ondataavailable = e => chunks.push(e.data)\n","  recorder.start()\n","  await sleep(time)\n","  recorder.onstop = async ()=>{\n","    blob = new Blob(chunks)\n","    text = await b2text(blob)\n","    resolve(text)\n","  }\n","  recorder.stop()\n","})\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["you said\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-11f79f6df346>\u001b[0m in \u001b[0;36m<cell line: 74>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0manvil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"server_2GGMSIC55EQPG6SUEFANETJL-LJWM672NOLIA5LJF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0manvil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anvil/server.py\u001b[0m in \u001b[0;36mwait_forever\u001b[0;34m()\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# all imports\n","from IPython.display import Javascript\n","from google.colab import output, files\n","from base64 import b64decode\n","from pydub import AudioSegment\n","from io import BytesIO\n","import whisper\n","import multiprocessing\n","import time\n","import threading\n","import queue\n","import anvil.server\n","\n","# Javascript for prompting local mic access\n","RECORD = \"\"\"\n","const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n","const b2text = blob => new Promise(resolve => {\n","  const reader = new FileReader()\n","  reader.onloadend = e => resolve(e.srcElement.result)\n","  reader.readAsDataURL(blob)\n","})\n","var record = time => new Promise(async resolve => {\n","  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n","  recorder = new MediaRecorder(stream)\n","  chunks = []\n","  recorder.ondataavailable = e => chunks.push(e.data)\n","  recorder.start()\n","  await sleep(time)\n","  recorder.onstop = async ()=>{\n","    blob = new Blob(chunks)\n","    text = await b2text(blob)\n","    resolve(text)\n","  }\n","  recorder.stop()\n","})\n","\"\"\"\n","#Function to ask for microphone access\n","def mic():\n","    display(Javascript(RECORD))\n","\n","# Function to listen for speech from user\n","def listen(sec):\n","  s = output.eval_js('record(%d)' % (sec*1000))\n","  b = b64decode(s.split(',')[1])\n","  audio = AudioSegment.from_file(BytesIO(b))\n","  return audio\n","\n","# Function to save audio from listen to wav file\n","def download(audio):\n","  audio_file = \"recorded_audio.wav\"\n","  audio.export(audio_file, format=\"wav\")\n","  #files.download(audio_file)\n","\n","#Function to transcribe audio\n","def translate():\n","  result = model.transcribe(\"/content/recorded_audio.wav\", language = \"en\")\n","  print(\"you said\" + result[\"text\"])\n","  return result[\"text\"]\n","\n","#Function to run the STT Model\n","@anvil.server.callable\n","def STT():\n","    mic()\n","    download(listen(3))\n","    return translate()\n","\n","\n","# Load whisper model, types: tiny, base, small, medium, large, large-v2\n","model = whisper.load_model(\"small\")\n","\n","#Connect to anvil server\n","anvil.server.connect(\"server_2GGMSIC55EQPG6SUEFANETJL-LJWM672NOLIA5LJF\")\n","\n","anvil.server.wait_forever()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"Lml4j79D7uxE","outputId":"7f71bd97-7f9e-4bb1-f718-e5cd81e7f30a","executionInfo":{"status":"error","timestamp":1723277178668,"user_tz":-480,"elapsed":112318,"user":{"displayName":"Logan","userId":"07369247524184233003"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n","const b2text = blob => new Promise(resolve => {\n","  const reader = new FileReader()\n","  reader.onloadend = e => resolve(e.srcElement.result)\n","  reader.readAsDataURL(blob)\n","})\n","var record = time => new Promise(async resolve => {\n","  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n","  recorder = new MediaRecorder(stream)\n","  chunks = []\n","  recorder.ondataavailable = e => chunks.push(e.data)\n","  recorder.start()\n","  await sleep(time)\n","  recorder.onstop = async ()=>{\n","    blob = new Blob(chunks)\n","    text = await b2text(blob)\n","    resolve(text)\n","  }\n","  recorder.stop()\n","})\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["speak now\n","speech is being translated\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-8f7968117a49>\u001b[0m in \u001b[0;36m<cell line: 121>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m# Wait for both threads to complete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0mproducer_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0mcommunicator_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0mtranslator_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# all imports\n","from IPython.display import Javascript\n","from google.colab import output, files\n","from base64 import b64decode\n","from pydub import AudioSegment\n","from io import BytesIO\n","import whisper\n","import time\n","import threading\n","import queue\n","\n","# Javascript for prompting local mic access\n","RECORD = \"\"\"\n","const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n","const b2text = blob => new Promise(resolve => {\n","  const reader = new FileReader()\n","  reader.onloadend = e => resolve(e.srcElement.result)\n","  reader.readAsDataURL(blob)\n","})\n","var record = time => new Promise(async resolve => {\n","  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n","  recorder = new MediaRecorder(stream)\n","  chunks = []\n","  recorder.ondataavailable = e => chunks.push(e.data)\n","  recorder.start()\n","  await sleep(time)\n","  recorder.onstop = async ()=>{\n","    blob = new Blob(chunks)\n","    text = await b2text(blob)\n","    resolve(text)\n","  }\n","  recorder.stop()\n","})\n","\"\"\"\n","\n","# Load whisper model, types: tiny, base, small, medium, large, large-v2\n","model = whisper.load_model(\"small\")\n","\n","#Function to ask for microphone access\n","def mic():\n","    display(Javascript(RECORD))\n","\n","# Function to listen for speech from user\n","def listen(sec):\n","  s = output.eval_js('record(%d)' % (sec*1000))\n","  b = b64decode(s.split(',')[1])\n","  audio = AudioSegment.from_file(BytesIO(b))\n","  return audio\n","\n","# Function to save audio from listen to wav file\n","def download(audio):\n","  audio_file = \"recorded_audio.wav\"\n","  audio.export(audio_file, format=\"wav\")\n","  #files.download(audio_file)\n","\n","#Transcribe audio\n","def translate():\n","  result = model.transcribe(\"/content/recorded_audio.wav\", language = \"en\")\n","  print(result[\"text\"])\n","\n","# Generator to save user speech into queue\n","def producer(speechQueue, speechLock):\n","    for i in range(3):\n","\n","      print(\"speak now\")\n","      speech = listen(3)\n","\n","      with speechLock:\n","        speechQueue.put(speech)\n","      print(\"speech added to speechQueue\")\n","\n","#middleman\n","def communicator(speechQueue, speechLock, event):\n","    while True:\n","      if not speechQueue.empty():\n","\n","        with speechLock:\n","          speech = speechQueue.get()\n","        print(\"Speech has been consumed\")\n","\n","        download(speech)\n","        event.set()\n","        print(\"speech added to translation queue\")\n","\n","# Translates audio segments from translation queue\n","def translator(event):\n","    while True:\n","\n","        print(\"speech is being translated\")\n","        event.wait()\n","        translate()\n","\n","        event.clear()\n","        print(\"speech has been translated\")\n","\n","# Create locks to ensure no deadlock\n","speechLock = threading.Lock()\n","\n","# Create an event\n","event = threading.Event()\n","\n","# Create queues for communication between threads\n","speechQueue = queue.Queue()\n","\n","# To access com mic\n","mic()\n","\n","# Create and start producer thread\n","producer_thread = threading.Thread(target=producer, args=(speechQueue, speechLock,), daemon=False)\n","producer_thread.start()\n","\n","# Create and start consumer thread\n","communicator_thread = threading.Thread(target=communicator, args=(speechQueue, speechLock, event,), daemon=False)\n","communicator_thread.start()\n","\n","#Create and start a translator thread\n","translator_thread = threading.Thread(target=translator, args=(event,), daemon=False)\n","translator_thread.start()\n","\n","# Wait for both threads to complete\n","producer_thread.join()\n","communicator_thread.join()\n","translator_thread.join()\n","\n","\n"]},{"cell_type":"code","source":["# all imports\n","from IPython.display import Javascript\n","from google.colab import output, files\n","from base64 import b64decode\n","from pydub import AudioSegment\n","from io import BytesIO\n","import whisper\n","import multiprocessing\n","import time\n","import threading\n","import queue\n","\n","\n","# Load whisper model, types: tiny, base, small, medium, large, large-v2\n","model = whisper.load_model(\"base\")\n","from pydub import AudioSegment\n","\n","# Load a non-empty audio segment (example: a WAV file)\n","audio = AudioSegment.from_file(\"/content/recorded_audio.wav\", format=\"wav\")\n","\n","# Function to save audio from listen to wav file and transcribe\n","for i in range(2):\n","  audio += audio\n","audio_file = \"/content/recorded_audio.wav\"\n","audio.export(audio_file, format=\"wav\")\n","result = model.transcribe(\"/content/recorded_audio.wav\")\n","files.download(audio_file)\n","return(result[\"text\"])\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"FNTp9h3Y2iqv","executionInfo":{"status":"error","timestamp":1723202592551,"user_tz":-480,"elapsed":89353,"user":{"displayName":"Logan Duran","userId":"11347927767109118147"}},"outputId":"d34ea31e-7dcf-4a3c-f382-7e53c5890863"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_cd027156-af6f-4ed4-a215-34b9a992c5d6\", \"recorded_audio.wav\", 4561964)"]},"metadata":{}},{"output_type":"error","ename":"SyntaxError","evalue":"'return' outside function (<ipython-input-12-464336b9d192>, line 28)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-464336b9d192>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    return(result[\"text\"])\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"af6fj5NsMzX4"},"outputs":[],"source":["\n","#All imports\n","import threading\n","import time\n","import queue\n","def mic():\n","    display(Javascript(RECORD))\n","\n","# Function to listen for speech from user\n","def listen(sec):\n","  s = output.eval_js('record(%d)' % (sec*1000))\n","  b = b64decode(s.split(',')[1])\n","  audio = AudioSegment.from_file(BytesIO(b))\n","  return audio\n","\n","# Function to save audio from listen to wav file and transcribe\n","def translate(audio):\n","  audio_file = \"recorded_audio.wav\"\n","  audio.export(audio_file, format=\"wav\")\n","  result = model.transcribe(\"/content/recorded_audio.wav\")\n","  #files.download(audio_file)\n","  return(result[\"text\"])\n","\n","\n","# Generator to save user speech into queue\n","def producer(speechQueue, lock):\n","    \"\"\"Generate data and put it into the queue.\"\"\"\n","    for i in range(2):\n","      print(\"speak now\")\n","      speech = listen(3)\n","      with lock:\n","        speechQueue.put(speech)\n","      print(\"speech added to speechQueue\")\n","\n","# Retriever for consuming speech from queue\n","def consumer(speechQueue, lock):\n","    \"\"\"Retrieve data from the queue and process it.\"\"\"\n","    while True:\n","      if not speechQueue.empty():\n","        print(\"Speech being translated\")\n","        with lock:\n","          speech = speechQueue.get()\n","        final = translate(speech)\n","        print(final)\n","\n","# Create a Queue for communication between threads\n","lock = threading.Lock()\n","speechQueue = queue.Queue()\n","mic()\n","\n","# Create and start producer thread, daemon so user can exit whenever they want\n","producer_thread = threading.Thread(target=producer, args=(speechQueue, lock,), daemon=False)\n","producer_thread.start()\n","\n","# Create and start consumer thread, daemon so user can exit whenever they want\n","consumer_thread = threading.Thread(target=consumer, args=(speechQueue, lock,), daemon=False)\n","consumer_thread.start()\n","\n","# Wait for both threads to complete\n","producer_thread.join()\n","consumer_thread.join()\n","\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}